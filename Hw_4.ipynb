{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4954874-9dac-4f43-ba95-aeeb97a6b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерація та надсилання даних від сенсора до Kafka\n",
    "from kafka import KafkaProducer\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "def generate_sensor_data(sensor_id):\n",
    "    temperature = random.uniform(25, 45)\n",
    "    humidity = random.uniform(15, 85)\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return {\n",
    "        'sensor_id': sensor_id,\n",
    "        'temperature': temperature,\n",
    "        'humidity': humidity,\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "\n",
    "def send_sensor_data(sensor_id, num_messages=10):\n",
    "    for _ in range(num_messages):\n",
    "        data = generate_sensor_data(sensor_id)\n",
    "        producer.send('building-sensors-maxim', value=data)\n",
    "        print(f\"Data sent: {data}\")\n",
    "        time.sleep(2)  \n",
    "\n",
    "sensor_id = random.randint(1, 1000)  \n",
    "send_sensor_data(sensor_id, num_messages=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6b8d5-7869-422d-8c2a-ea91fb820a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Обробка даних з Kafka з використанням ковзного вікна\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    'building-sensors-maxim',\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    group_id='sensor_group',\n",
    "    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    ")\n",
    "\n",
    "window_size = 60  \n",
    "sliding_interval = 1  \n",
    "watermark_duration = 10  \n",
    "window = deque() \n",
    "\n",
    "def calculate_averages(window):\n",
    "    total_temperature = sum([data['temperature'] for data in window])\n",
    "    total_humidity = sum([data['humidity'] for data in window])\n",
    "    count = len(window)\n",
    "    return total_temperature / count, total_humidity / count if count else 0\n",
    "\n",
    "def process_stream():\n",
    "    print(\"Starting to process the stream of data...\")\n",
    "    for message in consumer:\n",
    "        data = message.value\n",
    "        print(f\"Received message: {data}\")  \n",
    "        timestamp = datetime.strptime(data['timestamp'], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        window.append((timestamp, data))\n",
    "\n",
    "        while window and (timestamp - window[0][0]).total_seconds() > window_size + watermark_duration:\n",
    "            window.popleft()\n",
    "\n",
    "        if len(window) >= sliding_interval:\n",
    "            avg_temperature, avg_humidity = calculate_averages([d[1] for d in window])\n",
    "            print(f\"Avg Temperature: {avg_temperature:.2f}, Avg Humidity: {avg_humidity:.2f}\")\n",
    "\n",
    "        print(f\"Processed data: {data['sensor_id']} - Temperature: {data['temperature']}, Humidity: {data['humidity']} at {data['timestamp']}\")\n",
    "\n",
    "process_stream()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256efe33-f3d3-4364-b7f4-45aae4a2fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перевірка умов для алертів на основі отриманих даних\n",
    "import pandas as pd\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "\n",
    "alerts_conditions_path = r'K:\\PowerBi\\Go IT Magistr\\12_Data Engineering\\hw_4\\alerts_conditions.csv'\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    'building-sensors-maxim',\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    group_id='sensor_group',\n",
    "    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    ")\n",
    "\n",
    "alert_conditions_df = pd.read_csv(alerts_conditions_path)\n",
    "\n",
    "window_size = 60  \n",
    "sliding_interval = 1  \n",
    "watermark_duration = 10  \n",
    "window = deque()  \n",
    "\n",
    "def calculate_averages(window):\n",
    "    total_temperature = sum([data['temperature'] for data in window])\n",
    "    total_humidity = sum([data['humidity'] for data in window])\n",
    "    count = len(window)\n",
    "    return total_temperature / count, total_humidity / count if count else 0\n",
    "\n",
    "def check_alert_conditions(avg_temperature, avg_humidity, alert_conditions_df):\n",
    "    alert_conditions_df['avg_temperature'] = avg_temperature\n",
    "    alert_conditions_df['avg_humidity'] = avg_humidity\n",
    "\n",
    "    alerts = alert_conditions_df[\n",
    "        ((alert_conditions_df['min_temperature'] <= avg_temperature) | (alert_conditions_df['min_temperature'] == -999)) &\n",
    "        ((alert_conditions_df['max_temperature'] >= avg_temperature) | (alert_conditions_df['max_temperature'] == -999)) &\n",
    "        ((alert_conditions_df['min_humidity'] <= avg_humidity) | (alert_conditions_df['min_humidity'] == -999)) &\n",
    "        ((alert_conditions_df['max_humidity'] >= avg_humidity) | (alert_conditions_df['max_humidity'] == -999))\n",
    "    ]\n",
    "    return alerts\n",
    "\n",
    "def process_stream_with_alerts():\n",
    "    print(\"Starting to process the stream of data with alerts...\")\n",
    "    for message in consumer:\n",
    "        data = message.value\n",
    "        print(f\"Received message: {data}\")  \n",
    "        timestamp = datetime.strptime(data['timestamp'], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        window.append((timestamp, data))\n",
    "\n",
    "        while window and (timestamp - window[0][0]).total_seconds() > window_size + watermark_duration:\n",
    "            window.popleft()\n",
    "\n",
    "        if len(window) >= sliding_interval:\n",
    "            avg_temperature, avg_humidity = calculate_averages([d[1] for d in window])\n",
    "            print(f\"Avg Temperature: {avg_temperature:.2f}, Avg Humidity: {avg_humidity:.2f}\")\n",
    "\n",
    "            alerts = check_alert_conditions(avg_temperature, avg_humidity, alert_conditions_df)\n",
    "            if not alerts.empty:\n",
    "                for _, alert in alerts.iterrows():\n",
    "                    print(f\"Alert Triggered! {alert['alert_message']} (Code: {alert['alert_code']})\")\n",
    "\n",
    "        print(f\"Processed data: {data['sensor_id']} - Temperature: {data['temperature']}, Humidity: {data['humidity']} at {data['timestamp']}\")\n",
    "\n",
    "process_stream_with_alerts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd29215-fb05-4f8b-99f3-3db592c5096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запис алертів у Kafka-топік\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "def write_alerts_to_kafka(alerts):\n",
    "    for _, alert in alerts.iterrows():\n",
    "        alert_message = {\n",
    "            'window': {\n",
    "                'start': alert['window_start'],\n",
    "                'end': alert['window_end']\n",
    "            },\n",
    "            't_avg': alert['avg_temperature'],\n",
    "            'h_avg': alert['avg_humidity'],\n",
    "            'code': alert['alert_code'],\n",
    "            'message': alert['alert_message'],\n",
    "            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        producer.send('building-alerts-maxim', value=alert_message)\n",
    "        print(f\"Alert sent to Kafka: {alert_message}\")\n",
    "\n",
    "def process_stream_with_alerts_and_write_to_kafka():\n",
    "    print(\"Starting to process the stream of data with alerts...\")\n",
    "    for message in consumer:\n",
    "        data = message.value\n",
    "        print(f\"Received message: {data}\") \n",
    "        timestamp = datetime.strptime(data['timestamp'], '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        window.append((timestamp, data))\n",
    "\n",
    "        while window and (timestamp - window[0][0]).total_seconds() > window_size + watermark_duration:\n",
    "            window.popleft()\n",
    "\n",
    "        if len(window) >= sliding_interval:\n",
    "            avg_temperature, avg_humidity = calculate_averages([d[1] for d in window])\n",
    "            print(f\"Avg Temperature: {avg_temperature:.2f}, Avg Humidity: {avg_humidity:.2f}\")\n",
    "\n",
    "            alerts = check_alert_conditions(avg_temperature, avg_humidity, alert_conditions_df)\n",
    "            if not alerts.empty:\n",
    "                for _, alert in alerts.iterrows():\n",
    "                    print(f\"Alert Triggered! {alert['alert_message']} (Code: {alert['alert_code']})\")\n",
    "\n",
    "                    alert['window_start'] = window[0][0].strftime('%Y-%m-%dT%H:%M:%S.%f+03:00')\n",
    "                    alert['window_end'] = window[-1][0].strftime('%Y-%m-%dT%H:%M:%S.%f+03:00')\n",
    "                    alert['avg_temperature'] = avg_temperature\n",
    "                    alert['avg_humidity'] = avg_humidity\n",
    "\n",
    "                    write_alerts_to_kafka(alerts)\n",
    "\n",
    "        print(f\"Processed data: {data['sensor_id']} - Temperature: {data['temperature']}, Humidity: {data['humidity']} at {data['timestamp']}\")\n",
    "\n",
    "process_stream_with_alerts_and_write_to_kafka()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
